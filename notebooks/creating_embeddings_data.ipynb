{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "import wikipedia\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/articles_films.csv', sep=',', on_bad_lines='skip').title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:25,  1.63it/s]/home/et/miniconda3/envs/rag_poc/lib/python3.12/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/et/miniconda3/envs/rag_poc/lib/python3.12/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n",
      "3406it [43:58,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for i,d in tqdm(enumerate(data)):\n",
    "    try:\n",
    "        text = wikipedia.page(d).content.replace('\\n', ' ')\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        with open('../data/text_Film_theory.txt', 'a') as file:\n",
    "            file.write(text + '\\n')\n",
    "    except:\n",
    "        with open('../data/fails.txt', 'a') as file:\n",
    "            file.write(str(i) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('sade-adrien/redpajama_v2_sample_1M', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2', device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/text_Fields_of_mathematics_Mathematical_concepts_Mathematical_theorems.txt', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col = torch.zeros(13961, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "overlap = 300\n",
    "\n",
    "df = pd.DataFrame(columns=['text'] + [f'dim_{d}' for d in range(384)])\n",
    "i = overlap\n",
    "row = 0\n",
    "k = 0\n",
    "while i-overlap+chunk_size < len(data):\n",
    "    chunk = data[i-overlap: i-overlap+chunk_size]\n",
    "\n",
    "    encoded_input = tokenizer(chunk, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    #df.loc[row] = [chunk] + sentence_embeddings.squeeze().cpu().tolist()\n",
    "\n",
    "    all_col[k, :] = sentence_embeddings.squeeze().cpu()\n",
    "\n",
    "    i += chunk_size\n",
    "    row += 1\n",
    "    k += 1\n",
    "\n",
    "    print(i/len(data), row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_col_127= 4.9279375395599335e-33\n",
      "max_col_127= 1.632949732388289e-32\n",
      "std_col_127= 2.342806709949875e-33\n",
      "mean_col_223= -5.2916751646386895e-33\n",
      "max_col_223= 3.5809363589007665e-33\n",
      "std_col_223= 1.8979636480842274e-33\n",
      "mean_col_319= -5.2013259477234897e-08\n",
      "max_col_319= -2.2664535137550956e-08\n",
      "std_col_319= 6.7676584336595624e-09\n",
      "mean_col_200= -0.0026264037005603313\n",
      "max_col_200= 0.18293367326259613\n",
      "std_col_200= 0.047588448971509933\n",
      "mean_col_all= 0.0003472251701168716\n",
      "max_col_all= 0.26208481192588806\n",
      "std_col_all= 0.051029860973358154\n"
     ]
    }
   ],
   "source": [
    "for i in [127, 223, 319, 200]:\n",
    "    print(f'mean_col_{i}=', all_col[:, i].mean().item())\n",
    "    print(f'max_col_{i}=', all_col[:, i].max().item())\n",
    "    print(f'std_col_{i}=', all_col[:, i].std().item())\n",
    "\n",
    "print(f'mean_col_all=', all_col.mean().item())\n",
    "print(f'max_col_all=', all_col.max().item())\n",
    "print(f'std_col_all=', all_col.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor([ 4.9278e-36, -5.2915e-36, -5.2012e-11, -2.6263e-06,  3.4722e-07])\n",
      "max:  tensor([ 6.8799e-29, -7.3877e-29, -7.2616e-04, -3.6667e+01])\n"
     ]
    }
   ],
   "source": [
    "print('mean: ', torch.tensor(mean) / len(data))\n",
    "print('max: ', torch.tensor(maximum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/embeddings_films.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build embeddings 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f6288e97574983b2307f4eca0ffd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ce38729cb845ee8a2bdb37b34b2090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('sade-adrien/redpajama_v2_sample_1M', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Alibaba-NLP/gte-base-en-v1.5', device_map=device)\n",
    "model = AutoModel.from_pretrained('Alibaba-NLP/gte-base-en-v1.5', device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col = torch.zeros((1_000_000, 768), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "batch_size = 256\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    chunks = data[i:i+batch_size]['raw_content'][:chunk_size]\n",
    "    encoded_inputs = tokenizer(chunks, truncation=True, padding=True, max_length=1024, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_inputs)\n",
    "\n",
    "    sentence_embeddings = model_output.last_hidden_state[:, 0]\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    all_col[i:i+batch_size, :] = sentence_embeddings\n",
    "\n",
    "    print(i/len(data), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/embeddings1M.csv', all_col[:258].cpu(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_374</th>\n",
       "      <th>dim_375</th>\n",
       "      <th>dim_376</th>\n",
       "      <th>dim_377</th>\n",
       "      <th>dim_378</th>\n",
       "      <th>dim_379</th>\n",
       "      <th>dim_380</th>\n",
       "      <th>dim_381</th>\n",
       "      <th>dim_382</th>\n",
       "      <th>dim_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.051007</td>\n",
       "      <td>-0.012978</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.011717</td>\n",
       "      <td>-0.017226</td>\n",
       "      <td>0.099527</td>\n",
       "      <td>0.046106</td>\n",
       "      <td>-0.002129</td>\n",
       "      <td>0.096107</td>\n",
       "      <td>0.092475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>-0.066350</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>-0.028208</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>-0.013030</td>\n",
       "      <td>-0.037327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.124250</td>\n",
       "      <td>-0.026011</td>\n",
       "      <td>-0.018328</td>\n",
       "      <td>-0.008907</td>\n",
       "      <td>-0.012531</td>\n",
       "      <td>0.081328</td>\n",
       "      <td>0.048991</td>\n",
       "      <td>0.071464</td>\n",
       "      <td>0.052862</td>\n",
       "      <td>0.035286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014260</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.029491</td>\n",
       "      <td>-0.113279</td>\n",
       "      <td>-0.078890</td>\n",
       "      <td>-0.044626</td>\n",
       "      <td>-0.066180</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>-0.023522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009710</td>\n",
       "      <td>-0.006745</td>\n",
       "      <td>0.026349</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>-0.030031</td>\n",
       "      <td>0.093438</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>0.092181</td>\n",
       "      <td>0.145582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.037046</td>\n",
       "      <td>0.044612</td>\n",
       "      <td>-0.011689</td>\n",
       "      <td>0.017332</td>\n",
       "      <td>0.035664</td>\n",
       "      <td>-0.012586</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>-0.049236</td>\n",
       "      <td>-0.009235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.007143</td>\n",
       "      <td>-0.026577</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>-0.006410</td>\n",
       "      <td>0.044439</td>\n",
       "      <td>0.045105</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>0.065954</td>\n",
       "      <td>0.075059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.035422</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.093002</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>-0.050400</td>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>-0.026191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002157</td>\n",
       "      <td>-0.041576</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>-0.013392</td>\n",
       "      <td>-0.013451</td>\n",
       "      <td>0.026802</td>\n",
       "      <td>0.040362</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>0.084631</td>\n",
       "      <td>0.032822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.062008</td>\n",
       "      <td>0.085315</td>\n",
       "      <td>-0.046990</td>\n",
       "      <td>0.055014</td>\n",
       "      <td>-0.004234</td>\n",
       "      <td>-0.084269</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>-0.044174</td>\n",
       "      <td>-0.078543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13956</th>\n",
       "      <td>-0.091739</td>\n",
       "      <td>-0.020830</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-0.056864</td>\n",
       "      <td>0.035235</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.119695</td>\n",
       "      <td>0.092264</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>-0.045562</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>-0.064556</td>\n",
       "      <td>0.080322</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>-0.021374</td>\n",
       "      <td>0.057491</td>\n",
       "      <td>-0.010599</td>\n",
       "      <td>-0.081102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13957</th>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.015816</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>0.031980</td>\n",
       "      <td>0.039334</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.084143</td>\n",
       "      <td>0.097361</td>\n",
       "      <td>0.117580</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051010</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>-0.012729</td>\n",
       "      <td>-0.067720</td>\n",
       "      <td>0.033084</td>\n",
       "      <td>-0.017994</td>\n",
       "      <td>0.070195</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>-0.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>-0.074109</td>\n",
       "      <td>-0.098621</td>\n",
       "      <td>0.058788</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.068014</td>\n",
       "      <td>0.118665</td>\n",
       "      <td>0.046229</td>\n",
       "      <td>0.063646</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051419</td>\n",
       "      <td>0.058549</td>\n",
       "      <td>0.039828</td>\n",
       "      <td>-0.018397</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>-0.022283</td>\n",
       "      <td>-0.040176</td>\n",
       "      <td>0.019134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13959</th>\n",
       "      <td>-0.062486</td>\n",
       "      <td>-0.024779</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>-0.021990</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>0.073873</td>\n",
       "      <td>0.054727</td>\n",
       "      <td>0.058572</td>\n",
       "      <td>-0.032722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039516</td>\n",
       "      <td>-0.035085</td>\n",
       "      <td>-0.006046</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>-0.037108</td>\n",
       "      <td>-0.050757</td>\n",
       "      <td>0.056676</td>\n",
       "      <td>-0.067603</td>\n",
       "      <td>-0.020334</td>\n",
       "      <td>-0.022592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13960</th>\n",
       "      <td>-0.006912</td>\n",
       "      <td>-0.007745</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>-0.011684</td>\n",
       "      <td>-0.047834</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.017833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.043442</td>\n",
       "      <td>-0.040697</td>\n",
       "      <td>-0.039053</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>0.041348</td>\n",
       "      <td>0.023144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13961 rows Ã— 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dim_0     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
       "0     -0.051007 -0.012978 -0.004332 -0.011717 -0.017226  0.099527  0.046106   \n",
       "1     -0.124250 -0.026011 -0.018328 -0.008907 -0.012531  0.081328  0.048991   \n",
       "2      0.009710 -0.006745  0.026349  0.013770 -0.030031  0.093438  0.053371   \n",
       "3     -0.007143 -0.026577 -0.001916 -0.003471 -0.006410  0.044439  0.045105   \n",
       "4     -0.002157 -0.041576  0.032375 -0.013392 -0.013451  0.026802  0.040362   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13956 -0.091739 -0.020830  0.000524 -0.056864  0.035235 -0.025001  0.001402   \n",
       "13957 -0.128038 -0.015816  0.020297  0.031980  0.039334  0.010209  0.084143   \n",
       "13958 -0.074109 -0.098621  0.058788 -0.000985  0.013306  0.068014  0.118665   \n",
       "13959 -0.062486 -0.024779  0.041091 -0.021990  0.025752  0.019201  0.073873   \n",
       "13960 -0.006912 -0.007745  0.000188  0.015151  0.056152 -0.011684 -0.047834   \n",
       "\n",
       "          dim_7     dim_8     dim_9  ...   dim_374   dim_375   dim_376  \\\n",
       "0     -0.002129  0.096107  0.092475  ...  0.011735  0.050349  0.032294   \n",
       "1      0.071464  0.052862  0.035286  ...  0.014260  0.005386  0.029491   \n",
       "2      0.022237  0.092181  0.145582  ...  0.015877  0.037046  0.044612   \n",
       "3      0.018795  0.065954  0.075059  ...  0.004710  0.035422  0.066500   \n",
       "4     -0.001480  0.084631  0.032822  ...  0.008679  0.062008  0.085315   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "13956  0.119695  0.092264 -0.005016  ...  0.001604 -0.045562  0.009117   \n",
       "13957  0.097361  0.117580 -0.002334  ... -0.051010  0.057692  0.064038   \n",
       "13958  0.046229  0.063646 -0.010651  ... -0.051419  0.058549  0.039828   \n",
       "13959  0.054727  0.058572 -0.032722  ... -0.039516 -0.035085 -0.006046   \n",
       "13960  0.030134  0.040185  0.017833  ...  0.006360  0.017819  0.010589   \n",
       "\n",
       "        dim_377   dim_378   dim_379   dim_380   dim_381   dim_382   dim_383  \n",
       "0     -0.066350  0.010584  0.002566 -0.028208  0.046703 -0.013030 -0.037327  \n",
       "1     -0.113279 -0.078890 -0.044626 -0.066180  0.043084  0.005310 -0.023522  \n",
       "2     -0.011689  0.017332  0.035664 -0.012586  0.068374 -0.049236 -0.009235  \n",
       "3      0.093002  0.037736  0.091792 -0.050400  0.031015  0.012145 -0.026191  \n",
       "4     -0.046990  0.055014 -0.004234 -0.084269  0.010322 -0.044174 -0.078543  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "13956 -0.064556  0.080322  0.061112 -0.021374  0.057491 -0.010599 -0.081102  \n",
       "13957 -0.012729 -0.067720  0.033084 -0.017994  0.070195  0.011426 -0.015970  \n",
       "13958 -0.018397 -0.046813  0.004026  0.058502 -0.022283 -0.040176  0.019134  \n",
       "13959  0.010948 -0.037108 -0.050757  0.056676 -0.067603 -0.020334 -0.022592  \n",
       "13960  0.043442 -0.040697 -0.039053  0.064102 -0.001340  0.041348  0.023144  \n",
       "\n",
       "[13961 rows x 384 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/embeddings_maths.csv', usecols=[i for i in range(2, 386)])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/embeddings_maths.txt', sep=' ', float_format='%.6f', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from gnews import GNews\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/06/2024 09:56:19 AM - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-l6-v2\n"
     ]
    }
   ],
   "source": [
    "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "                            model_name=embedding_model,\n",
    "                            model_kwargs={'device': device},\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embeddings.embed_query(\"Why was Sam Altman fired from OpenAI in November 2023?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
